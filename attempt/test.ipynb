{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IntProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/attempt_env/lib/python3.8/site-packages/tqdm-4.27.0-py3.8.egg/tqdm/_tqdm_notebook.py:103\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m total:\n\u001b[0;32m--> 103\u001b[0m     pbar \u001b[39m=\u001b[39m IntProgress(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mtotal)\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# No total? Show info style bar with no progress tqdm status\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IntProgress' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> 2\u001b[0m mrpc \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuper_glue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmultirc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m mrpc\n",
      "File \u001b[0;32m~/miniconda3/envs/attempt_env/lib/python3.8/site-packages/datasets/load.py:711\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, script_version, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m ignore_verifications \u001b[39m=\u001b[39m ignore_verifications \u001b[39mor\u001b[39;00m save_infos\n\u001b[1;32m    710\u001b[0m \u001b[39m# Download/copy dataset processing script\u001b[39;00m\n\u001b[0;32m--> 711\u001b[0m module_path, \u001b[39mhash\u001b[39m, resolved_file_path \u001b[39m=\u001b[39m prepare_module(\n\u001b[1;32m    712\u001b[0m     path,\n\u001b[1;32m    713\u001b[0m     script_version\u001b[39m=\u001b[39;49mscript_version,\n\u001b[1;32m    714\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m    715\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m    716\u001b[0m     dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    717\u001b[0m     return_resolved_file_path\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    718\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    719\u001b[0m )\n\u001b[1;32m    720\u001b[0m \u001b[39m# Set the base path for downloads as the parent of the script location\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[39mif\u001b[39;00m resolved_file_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/attempt_env/lib/python3.8/site-packages/datasets/load.py:323\u001b[0m, in \u001b[0;36mprepare_module\u001b[0;34m(path, script_version, download_config, download_mode, dataset, force_local_path, dynamic_modules_path, return_resolved_file_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m file_path \u001b[39m=\u001b[39m hf_github_url(path\u001b[39m=\u001b[39mpath, name\u001b[39m=\u001b[39mname, dataset\u001b[39m=\u001b[39mdataset, version\u001b[39m=\u001b[39mscript_version)\n\u001b[1;32m    322\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 323\u001b[0m     local_path \u001b[39m=\u001b[39m cached_path(file_path, download_config\u001b[39m=\u001b[39;49mdownload_config)\n\u001b[1;32m    324\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[39mif\u001b[39;00m script_version \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/attempt_env/lib/python3.8/site-packages/datasets/utils/file_utils.py:281\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     url_or_filename \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(url_or_filename)\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    280\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    282\u001b[0m         url_or_filename,\n\u001b[1;32m    283\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    284\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[1;32m    285\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    286\u001b[0m         resume_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mresume_download,\n\u001b[1;32m    287\u001b[0m         user_agent\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muser_agent,\n\u001b[1;32m    288\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mlocal_files_only,\n\u001b[1;32m    289\u001b[0m         use_etag\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_etag,\n\u001b[1;32m    290\u001b[0m         max_retries\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    291\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_auth_token,\n\u001b[1;32m    292\u001b[0m     )\n\u001b[1;32m    293\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    294\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m~/miniconda3/envs/attempt_env/lib/python3.8/site-packages/datasets/utils/file_utils.py:663\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, use_auth_token)\u001b[0m\n\u001b[1;32m    661\u001b[0m         ftp_get(url, temp_file)\n\u001b[1;32m    662\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 663\u001b[0m         http_get(\n\u001b[1;32m    664\u001b[0m             url,\n\u001b[1;32m    665\u001b[0m             temp_file,\n\u001b[1;32m    666\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    667\u001b[0m             resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m    668\u001b[0m             headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    669\u001b[0m             cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m    670\u001b[0m             max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    671\u001b[0m         )\n\u001b[1;32m    673\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, cache_path)\n\u001b[1;32m    674\u001b[0m shutil\u001b[39m.\u001b[39mmove(temp_file\u001b[39m.\u001b[39mname, cache_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/attempt_env/lib/python3.8/site-packages/datasets/utils/file_utils.py:489\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, cookies, timeout, max_retries)\u001b[0m\n\u001b[1;32m    487\u001b[0m total \u001b[39m=\u001b[39m resume_size \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(content_length) \u001b[39mif\u001b[39;00m content_length \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    488\u001b[0m not_verbose \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(logger\u001b[39m.\u001b[39mgetEffectiveLevel() \u001b[39m>\u001b[39m WARNING)\n\u001b[0;32m--> 489\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[1;32m    490\u001b[0m     unit\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    491\u001b[0m     unit_scale\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m     total\u001b[39m=\u001b[39;49mtotal,\n\u001b[1;32m    493\u001b[0m     initial\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m    494\u001b[0m     desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDownloading\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    495\u001b[0m     disable\u001b[39m=\u001b[39;49mnot_verbose,\n\u001b[1;32m    496\u001b[0m )\n\u001b[1;32m    497\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m    498\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/attempt_env/lib/python3.8/site-packages/tqdm-4.27.0-py3.8.egg/tqdm/_tqdm_notebook.py:211\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mncols \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m100\u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_ncols \u001b[39melse\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mncols\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    210\u001b[0m \u001b[39m# Replace with IPython progress bar display (with correct total)\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus_printer(\n\u001b[1;32m    212\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtotal, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdesc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncols)\n\u001b[1;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdesc \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# trick to place description before the bar\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39m# Print initial bar state\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/attempt_env/lib/python3.8/site-packages/tqdm-4.27.0-py3.8.egg/tqdm/_tqdm_notebook.py:110\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    107\u001b[0m         pbar\u001b[39m.\u001b[39mbar_style \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39minfo\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNameError\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[39m# #187 #451 #558\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIntProgress not found. Please update jupyter and ipywidgets.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m See https://ipywidgets.readthedocs.io/en/stable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m/user_install.html\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m desc:\n\u001b[1;32m    116\u001b[0m     pbar\u001b[39m.\u001b[39mdescription \u001b[39m=\u001b[39m desc\n",
      "\u001b[0;31mImportError\u001b[0m: IntProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "mrpc = load_dataset('super_glue', 'multirc')\n",
    "mrpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "lora_dict = torch.load('/mlx_devbox/users/linzhisheng.2021/ATTEMPT/attempt/outputs/lora/pytorch_model.bin', map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "print(lora_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.block.0.layer.1.DenseReluDense.wi.weight tensor([[ 0.1434,  0.1963, -0.0368,  ...,  0.4928, -0.1723,  0.0048],\n",
      "        [ 0.1951, -0.1751, -0.6519,  ..., -0.6255,  0.1332, -0.4499],\n",
      "        [-0.1292,  0.1082, -0.1376,  ...,  0.2967, -0.1191,  0.0063],\n",
      "        ...,\n",
      "        [ 0.5555, -0.4951, -0.0063,  ..., -0.3699,  0.6350, -0.3813],\n",
      "        [ 0.3053, -0.0576,  0.2650,  ...,  0.4730, -0.5499, -0.7927],\n",
      "        [ 0.1196, -0.3631,  0.1581,  ...,  0.2577, -0.3358, -0.1690]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = torch.load('/root/.cache/huggingface/transformers/ab4e948915b067f5cb6e5105f6f85044fd717b133f43240db67899a8fc7b29a2.26934c75adf19ceac3c268b721ba353356b7609c45f5627550326f275a2163b4', map_location=torch.device('cpu'))\n",
    "test.keys()\n",
    "\n",
    "for k,v in lora_dict.items():\n",
    "    if  k=='encoder.block.0.layer.1.DenseReluDense.wi.weight' and not torch.equal(v, test[k]):\n",
    "        \n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder.block.0.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.0.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.0.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.0.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.1.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.1.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.1.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.1.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.2.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.2.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.2.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.2.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.3.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.3.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.3.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.3.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.4.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.4.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.4.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.4.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.5.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.5.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.5.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.5.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.6.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.6.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.6.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.6.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.7.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.7.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.7.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.7.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.8.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.8.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.8.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.8.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.9.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.9.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.9.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.9.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.10.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.10.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.10.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.10.layer.1.DenseReluDense.wo.lora_B', 'encoder.block.11.layer.1.DenseReluDense.wi.lora_A', 'encoder.block.11.layer.1.DenseReluDense.wi.lora_B', 'encoder.block.11.layer.1.DenseReluDense.wo.lora_A', 'encoder.block.11.layer.1.DenseReluDense.wo.lora_B', 'decoder.block.0.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.0.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.0.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.0.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.1.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.1.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.1.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.1.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.2.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.2.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.2.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.2.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.3.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.3.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.3.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.3.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.4.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.4.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.4.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.4.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.5.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.5.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.5.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.5.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.6.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.6.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.6.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.6.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.7.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.7.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.7.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.7.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.8.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.8.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.8.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.8.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.9.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.9.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.9.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.9.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.10.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.10.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.10.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.10.layer.2.DenseReluDense.wo.lora_B', 'decoder.block.11.layer.2.DenseReluDense.wi.lora_A', 'decoder.block.11.layer.2.DenseReluDense.wi.lora_B', 'decoder.block.11.layer.2.DenseReluDense.wo.lora_A', 'decoder.block.11.layer.2.DenseReluDense.wo.lora_B'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.load('/mlx_devbox/users/linzhisheng.2021/ATTEMPT/attempt/outputs/lora/lora.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "test.keys()"
   ]
  }
 ],
 "metadata": {
  "fileId": "b1110c67-f08d-4807-bac5-97a9cee85a9e",
  "kernelspec": {
   "display_name": "Python 3.8.18 ('attempt_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e049aeb05306112ea1bcfc9abe07367b26b4c6a55b999ecd388f17ad162f926"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
